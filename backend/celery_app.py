"""
Configuraci√≥n de Celery para procesamiento as√≠ncrono
"""
from celery import Celery
from config import get_config
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Obtener configuraci√≥n
config = get_config()

# Crear instancia de Celery
celery = Celery(
    'seira',
    broker=config.CELERY_BROKER_URL,
    backend=config.CELERY_RESULT_BACKEND
)

# Configuraci√≥n optimizada para procesamiento masivo
celery.conf.update(
    # Workers
    worker_concurrency=config.MAX_WORKERS,
    worker_prefetch_multiplier=4,
    worker_max_tasks_per_child=1000,  # Reiniciar worker cada 1000 tareas para liberar memoria
    
    # Tasks
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='America/Guatemala',
    enable_utc=True,
    
    # Resultados
    result_expires=3600,  # Los resultados expiran en 1 hora
    
    # Retry y confiabilidad
    task_acks_late=True,  # Confirmar tarea solo despu√©s de completarla
    task_reject_on_worker_lost=True,
    
    # Routing - diferentes colas para diferentes tipos de tareas
    task_routes={
        'backend.tasks.process_tickets.*': {'queue': 'nlp'},
        'backend.tasks.generate_reports.*': {'queue': 'reports'},
    },
    
    # L√≠mites de tiempo
    task_time_limit=1800,  # 30 minutos m√°ximo por tarea
    task_soft_time_limit=1500,  # Warning a los 25 minutos
    
    # Configuraci√≥n de retry
    task_default_retry_delay=60,  # Reintentar despu√©s de 1 minuto
    task_max_retries=3,
)

# Auto-discover tasks en el m√≥dulo backend.tasks
celery.autodiscover_tasks(['backend.tasks'])

logger.info("‚úÖ Celery configurado correctamente")
logger.info(f"üì° Broker: {config.CELERY_BROKER_URL}")
logger.info(f"üíæ Backend: {config.CELERY_RESULT_BACKEND}")
logger.info(f"üë∑ Workers concurrentes: {config.MAX_WORKERS}")